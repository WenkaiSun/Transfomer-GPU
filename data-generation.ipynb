{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4483f492-e89b-4761-b553-e072a3a73951",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94da59b1-0759-43ad-b98c-7b023bb61ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28dbab-0e60-482a-bcd3-405f7e85525e",
   "metadata": {},
   "source": [
    "### Dummy Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa1e5046-cccb-40a8-ba5c-d5563d1b6608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size (in GB): 0.15 GB\n",
      "Data shape: torch.Size([100, 1024, 384])\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)  # Set seed for CPU operations\n",
    "torch.cuda.manual_seed_all(seed)  # Set seed for all GPU operations (if using CUDA)\n",
    "torch.backends.cudnn.deterministic = True  # Ensure deterministic behavior for CuDNN backend\n",
    "torch.backends.cudnn.benchmark = False  # Disable the auto-tuner for benchmarking (for reproducibility)\n",
    "\n",
    "sequence_length = 1024 \n",
    "embedding_dim = 384 \n",
    "batch_size = 100\n",
    " \n",
    "# N x A x B (N = batch size, A = sequence_length, B = embedding_dimension)\n",
    "dummy_input = torch.randn(batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "data_size_gb = dummy_input.nbytes / (1024 ** 3)\n",
    "print(\"Data size (in GB): {:.2f} GB\".format(data_size_gb))\n",
    "print(\"Data shape:\", dummy_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "684c4e74-3c0b-4e10-88ee-f15d35302527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This input can be called from CUDA and C++ by using the codes below.\n",
    "\n",
    "# // Loading library\n",
    "# include <torch/torch.h>\n",
    "\n",
    "# // Loading the tensor from the .pt file\n",
    "# torch::Tensor dummy_input = torch::load(\"dummy_input.pt\");\n",
    "\n",
    "# // Moving the tensor to CPU \n",
    "# dummy_input = dummy_input.to(torch::kCPU);\n",
    "\n",
    "# // Moving the tensor to CUDA \n",
    "# dummy_input = dummy_input.to(torch::kCUDA);\n",
    "\n",
    "torch.save(dummy_input, \"dummy_input.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5875930-3435-4f25-95f7-1bfd3dd1dd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=384, out_features=384, bias=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Linear(embedding_dim, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fe138f-dfa9-45f3-9894-a28c7fd84316",
   "metadata": {},
   "source": [
    "### Single-Head Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead641fb-aca1-443a-b284-b5686e260b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_length, embed_dim)\n",
    "        Q = self.query(x)  # (batch_size, seq_length, embed_dim)\n",
    "        K = self.key(x)    # (batch_size, seq_length, embed_dim)\n",
    "        V = self.value(x)  # (batch_size, seq_length, embed_dim)\n",
    "        \n",
    "        # Compute attention scores\n",
    "        scores = torch.bmm(Q, K.transpose(1, 2))  # (batch_size, seq_length, seq_length)\n",
    "        scores = scores / (self.embed_dim ** 0.5)  # Scale scores\n",
    "        attention_weights = self.softmax(scores)  # (batch_size, seq_length, seq_length)\n",
    "        \n",
    "        # Weighted sum of values\n",
    "        attention_output = torch.bmm(attention_weights, V)  # (batch_size, seq_length, embed_dim)\n",
    "        return attention_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f81af45-1b9f-4e74-9b95-33613cfb2eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: torch.Size([100, 1024, 384])\n",
      "Attention Weights Shape: torch.Size([100, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "self_attention = SelfAttention(embedding_dim)\n",
    "\n",
    "self_attention_output, self_attention_weights = self_attention(dummy_input)\n",
    "\n",
    "print(\"Output Shape:\", self_attention_output.shape) \n",
    "print(\"Attention Weights Shape:\", self_attention_weights.shape)  \n",
    "\n",
    "torch.save(self_attention_output, \"self_attention_output.pt\")\n",
    "torch.save(self_attention_weights, \"self_attention_weights.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e05f0fb-f5d7-457c-88ec-103edef80bd6",
   "metadata": {},
   "source": [
    "### Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8085feb5-7fa2-46c4-8e18-bf01ddf830bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_query = nn.Linear(embedding_dim, embedding_dim)\n",
    "linear_key = nn.Linear(embedding_dim, embedding_dim)\n",
    "linear_value = nn.Linear(embedding_dim, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "998e11cc-1e2f-4fd9-8c77-a67b64e69d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output Shape: torch.Size([100, 1024, 384])\n",
      "Attention Weights Shape: torch.Size([100, 1024, 1024])\n"
     ]
    }
   ],
   "source": [
    "multihead_attention = nn.MultiheadAttention(embed_dim=embedding_dim, num_heads=4, batch_first=True)\n",
    "\n",
    "query = linear_query(dummy_input)\n",
    "key = linear_key(dummy_input)\n",
    "value = linear_value(dummy_input)\n",
    "\n",
    "multihead_attention_output, multihead_attention_weights = multihead_attention(query, key, value)\n",
    "\n",
    "print(\"Output Shape:\", multihead_attention_output.shape) \n",
    "print(\"Attention Weights Shape:\", multihead_attention_weights.shape)  \n",
    "\n",
    "torch.save(self_attention_output, \"multihead_attention_output.pt\")\n",
    "torch.save(self_attention_weights, \"multihead_attention_weights.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
